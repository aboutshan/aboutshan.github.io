<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Shan Zhong</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
	<body class="is-preload">
	
		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="../images/1.png" alt="" /></span>
					<h1 id="logo"><a href="../index.html">Shan Zhong</a></h1>
					
				</header>
				<nav id="nav">
					<ul>
						<li><h4><a href="../index.html">Home Page</a></h4></li>
						<li><a href="#two" class="active">Graph Embedding</a></li>
						
					</ul>
				</nav>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
							
								<div class="container">
									<header class="major">
										<h2>Graph Embedding</h2>
										<blockquote><h3 style="color:grey">Nowadays, it's easier to define what is not a graph(network).</h3></blockquote>
									</header>
									<p></p>
								</div>
							</section>


						<!-- Two -->
							<section id="two">
								<div class="container">
									
										<article>
											<style>
												.font_bk{border:2px solid #ccc;}
												</style>
												<h3 align="left"><span class="font_bk">Hyperbolic Graph Embedding</span></h3>
											<center>
											<img src="../images/tree.JPG"  width="400",height="400"/></center>
											
										

												<p> It is common in  machine learning to represent data as being embedded in a Euclidean space. Hyperbolic space is believed to be better than its Euclidean counterpart to represent data that is tree-like or 
													has latent hierarchical architecture. The exponential growth of the PoincarÂ´e surface area with respect to its radius 
													is analogous to the exponential growth of the number of leaves in a tree with respect to its depth, 
													rather than polynomially as in the Euclidean case. Finding good low-dimensional embeddings of network data is a challenging and rewarding task.</p>
												
												<!-- <h3 align="left">Our work (Highlight: Innovative work!)
												</h4>
												<p>We provide a data-driven machine learning method (Principal Component Analysis) to discover new flow observables, which 
												are better indicators for initial fluctuations than traditional fourier flow harmonics.</p>
												<p style="color:black"> This work has been presented by me on 4th China LHC Physics Conference (Oral). If you are interested,
												<a href="../pdfs/pca_wuhan.pdf">click me to get the slides.</a> </p>
												<p style="color:black">The paper is in preparation and will be soon submitted. 
												<br/>Title: Principal Component Analysis of Collective Flow in Relativistic Heavy-Ion Collisions
												<br/>Collaborators: <a href="https://www.researchgate.net/profile/Huichao_Song2">HuiChao Song</a>,
												<a href="https://www.researchgate.net/scientific-contributions/2125512557_Wenbin_Zhao">Wenbin Zhao</a> -->
											
										</article>
										
									
								</div>
							</section>
							
							 
							<!-- Three -->
							<!--
							<section id="three">
								<div class="container">
									
										<article>
											<style>
												.font_bk{border:2px solid #ccc;}
												</style>
												<h3 align="left"><span class="font_bk">Network Geometry</span></h3>
											<center>
											<img src="../images/geometry.JPG"  width="600",height="350"/></center>
											
												
												
												
										
												<h3 align="left">Our work
												</h4>
												<p>We apply four-point delta statistics to evaluate Gromov hyperbolicity on various network datasets, 
													thus arriving at an approximate idea of the geometry of the underlying manifold of the networks.</p>
												
										</article>
										
									
								</div>
							</section>-->
						    
<!-- Four -->
<section id="three">
	<div class="container">
		
			<article>
				<style>
					.font_bk{border:2px solid #ccc;}
					</style>
					<h3 align="left"><span class="font_bk">Network Science Inspired ANN Sparse Training</span></h3>
				<center>
				<img src="../images/sparse_train.JPG"  width="650",height="350"/></center>
				
					
					
					
			
					<h3 align="left">
					</h4>
					<p>(Figure from Nat Commun 9, 2383 (2018)) </p>
					<p >Our group is trying to take inspiration from network properties of biological neural
						 networks (e.g. sparsity) to help efficiently train artificial neural networks (ANNs).</p>
					<!-- <p style="color:black"> This work is the final essay of Seminars for Quantum Mechanics in 2018 Spring, Peking University.
					<a href="../pdfs/bag_model.pdf">click me to get the paper.</a>
					</br> Collaborators: Mingyang Duan</br>Instructor: <a href="http://www.phy.pku.edu.cn/chinese/renyuan/liuyuxin.htm">Yuxin Liu</a>.</p> -->
				
			</article>
			
		
	</div>
</section>


					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Shan Zhong. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>